{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn import tree as tr\n",
    "from sklearn import model_selection as ms\n",
    "from six import StringIO\n",
    "import cv2\n",
    "import matplotlib as plt\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('../datasets/regression/X_training.csv')\n",
    "y_train = pd.read_csv('../datasets/regression/y_training.csv')\n",
    "\n",
    "\n",
    "x_val = pd.read_csv('../datasets/regression/X_validation.csv')\n",
    "y_val = pd.read_csv('../datasets/regression/y_val.csv')\n",
    "\n",
    "\n",
    "x_test = pd.read_csv('../datasets/regression/X_test.csv')\n",
    "y_test = pd.read_csv('../datasets/regression/y_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_model = LinearRegression()\n",
    "# lr_model.fit(x_train, y_train)\n",
    "\n",
    "# yhat_val = lr_model.predict(x_val)\n",
    "\n",
    "\n",
    "# r2_squared = mt.r2_score( y_val, yhat_val )\n",
    "# print( 'R2 square: {}'.format( r2_squared ) )\n",
    "\n",
    "# mse = mt.mean_squared_error(y_val,yhat_val)\n",
    "\n",
    "# print( 'Mean Squared Error: {}'.format( mse ) )\n",
    "\n",
    "\n",
    "# rmse = mt.root_mean_squared_error(y_val,yhat_val)\n",
    "# print('Root Mean Squared Error: {}'.format(rmse) )  \n",
    "  \n",
    "\n",
    "\n",
    "# mae = mt.mean_absolute_error(y_val, yhat_val)\n",
    "# print('Mean Absolute Error: {}'.format(mae) )\n",
    "\n",
    "# mape = mt.mean_absolute_percentage_error(y_val, yhat_val)\n",
    "# print('Mean Absolute Percentage Error: {}'.format(mape) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_last = LinearRegression()\n",
    "# model_last.fit(pd.concat([x_train,x_val], ignore_index=True), pd.concat([y_train,y_val], ignore_index = True) ) \n",
    "# #  model_last.fit(pd.concat([x_train,x_validation], ignore_index=True), pd.concat([y_train,y_validation], ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhat_test = model_last.predict(x_test)\n",
    "# r2_squared = mt.r2_score( y_test, yhat_test )\n",
    "# print( 'R2 square: {}'.format( r2_squared ) )\n",
    "\n",
    "# mse = mt.mean_squared_error(y_test,yhat_test)\n",
    "\n",
    "# print( 'Mean Squared Error: {}'.format( mse ) )\n",
    "\n",
    "\n",
    "# rmse = mt.root_mean_squared_error(y_test,yhat_test)\n",
    "# print('Root Mean Squared Error: {}'.format(rmse) )  \n",
    "  \n",
    "\n",
    "\n",
    "# mae = mt.mean_absolute_error(y_test, yhat_test)\n",
    "# print('Mean Absolute Error: {}'.format(mae) )\n",
    "\n",
    "# mape = mt.mean_absolute_percentage_error(y_test, yhat_test)\n",
    "# print('Mean Absolute Percentage Error: {}'.format(mape) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhat_train = model_last.predict(x_train)\n",
    "\n",
    "\n",
    "# r2_squared = mt.r2_score( y_train, yhat_train )\n",
    "# print( 'R2 square: {}'.format( r2_squared ) )\n",
    "\n",
    "# mse = mt.mean_squared_error(y_train,yhat_train)\n",
    "\n",
    "# print( 'Mean Squared Error: {}'.format( mse ) )\n",
    "\n",
    "\n",
    "# rmse = mt.root_mean_squared_error(y_train,yhat_train)\n",
    "# print('Root Mean Squared Error: {}'.format(rmse) )  \n",
    "  \n",
    "\n",
    "\n",
    "# mae = mt.mean_absolute_error(y_train, yhat_train)\n",
    "# print('Mean Absolute Error: {}'.format(mae) )\n",
    "\n",
    "# mape = mt.mean_absolute_percentage_error(y_train, yhat_train)\n",
    "# print('Mean Absolute Percentage Error: {}'.format(mape) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_list = (i for i in range(1,32))   \n",
    "# val_scores = list()\n",
    "\n",
    "\n",
    "# for i in iter_list:\n",
    "# # Instanciando e treinando a Decision Tree Regressor\n",
    "#     tree_reg = tr.DecisionTreeRegressor(max_depth = i)\n",
    "#     tree_reg.fit(x_train, y_train)\n",
    "#     # Realizando a predição com os dados de validacao\n",
    "#     yhat_val = tree_reg.predict(x_val)\n",
    "#     scores = {\n",
    "#         'max_depth': i,\n",
    "#         'r2': mt.r2_score(y_val, yhat_val),\n",
    "#         'mse': mt.mean_squared_error(y_val, yhat_val),\n",
    "#         'rmse': mt.root_mean_squared_error(y_val, yhat_val),\n",
    "#         'mae': mt.mean_absolute_error(y_val, yhat_val),\n",
    "#         'mape': mt.mean_absolute_percentage_error(y_val,yhat_val)\n",
    "#       }\n",
    "#     val_scores.append(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encontrar o dicionário com o melhor valor de rmse\n",
    "# best_rmse = max(val_scores, key=lambda x: x['rmse'])\n",
    "\n",
    "# # Exibir o valor de k e o valor de rmse correspondente\n",
    "# print(f\"Melhor valor de rmse: {best_rmse['rmse']} com max_depth = {best_rmse['max_depth']}\")\n",
    "# print(f\"r2: {best_rmse['r2']}\")\n",
    "# print(f\"mse: {best_rmse['mse']}\")\n",
    "# print(f\"rmse {best_rmse['rmse']}\")\n",
    "# print(f\"mae {best_rmse['mae']}\")\n",
    "# print(f\"mape {np.round(best_rmse['mape'], 2) }%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_last = tr.DecisionTreeRegressor( max_depth= 24  )\n",
    "# model_last.fit(pd.concat([x_train,x_val], ignore_index=True), pd.concat([y_train,y_val], ignore_index=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Previsão sobre os dados de treino\n",
    "# yhat_train = model_last.predict( x_train )\n",
    "# r2_train = mt.r2_score(y_train, yhat_train)\n",
    "# mse_train  = mt.mean_squared_error( y_train, yhat_train )  \n",
    "# rmse_train = mt.root_mean_squared_error(y_train,yhat_train)\n",
    "# mae  = mt.mean_absolute_error( y_train, yhat_train )\n",
    "# mape = mt.mean_absolute_percentage_error( y_train,yhat_train )\n",
    "\n",
    "\n",
    "# print(f\"r2_train: {r2_train}\")\n",
    "# print(f\"mse_train: {mse_train}\")\n",
    "# print(f\"rmse_train: {rmse_train}\")\n",
    "# print(f\"mae_train: {mae}\")\n",
    "# print(f'mape_train: {mape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Previsão sobre os dados de validacao\n",
    "# yhat_val = model_last.predict( x_val )\n",
    "# r2_val = mt.r2_score(y_val, yhat_val)\n",
    "# mse_val  = mt.mean_squared_error( y_val, yhat_val )  \n",
    "# rmse_val = mt.root_mean_squared_error(y_val,yhat_val)\n",
    "# mae  = mt.mean_absolute_error( y_val, yhat_val )\n",
    "# mape = mt.mean_absolute_percentage_error( y_val,yhat_val )\n",
    "\n",
    "\n",
    "# print(f\"r2_val: {r2_val}\")\n",
    "# print(f\"mse_val: {mse_val}\")\n",
    "# print(f\"rmse_val: {rmse_val}\")\n",
    "# print(f\"mae_val: {mae}\")\n",
    "# print(f'mape_val: {mape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Previsão sobre os dados de teste\n",
    "# yhat_test = model_last.predict( x_test )\n",
    "# r2_test = mt.r2_score(y_test, yhat_test)\n",
    "# mse_test  = mt.mean_squared_error( y_test, yhat_test )  \n",
    "# rmse_test = mt.root_mean_squared_error(y_test,yhat_test)\n",
    "# mae  = mt.mean_absolute_error( y_test, yhat_test )\n",
    "# mape = mt.mean_absolute_percentage_error( y_test,yhat_test )\n",
    "\n",
    "\n",
    "# print(f\"r2_test: {r2_test}\")\n",
    "# print(f\"mse_test: {mse_test}\")\n",
    "# print(f\"rmse_test: {rmse_test}\")\n",
    "# print(f\"mae_test: {mae}\")\n",
    "# print(f'mape_test: {mape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_list = (i for i in range(1, 32))\n",
    "# val_scores = list()\n",
    "\n",
    "# for i in iter_list:\n",
    "#     # Instanciando e treinando o Random Forest Regressor\n",
    "#     rf_reg = RandomForestRegressor(max_depth=i, random_state=42)\n",
    "#     rf_reg.fit(x_train, y_train)\n",
    "    \n",
    "#     # Realizando a predição com os dados de validação\n",
    "#     yhat_val = rf_reg.predict(x_val)\n",
    "    \n",
    "#     # Calculando as métricas\n",
    "#     scores = {\n",
    "#         'max_depth': i,\n",
    "#         'r2': mt.r2_score(y_val, yhat_val),\n",
    "#         'mse': mt.mean_squared_error(y_val, yhat_val),\n",
    "#         'rmse': mt.mean_squared_error(y_val, yhat_val, squared=False),  # Aqui o rmse\n",
    "#         'mae': mt.mean_absolute_error(y_val, yhat_val),\n",
    "#         'mape': mt.mean_absolute_percentage_error(y_val, yhat_val)\n",
    "#     }\n",
    "    \n",
    "#     val_scores.append(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encontrar o dicionário com o melhor valor de rmse\n",
    "# best_rmse = max(val_scores, key=lambda x: x['rmse'])\n",
    "\n",
    "# # Exibir o valor de k e o valor de rmse correspondente\n",
    "# print(f\"Melhor valor de rmse: {best_rmse['rmse']} com max_depth = {best_rmse['max_depth']}\")\n",
    "# print(f\"r2: {best_rmse['r2']}\")\n",
    "# print(f\"mse: {best_rmse['mse']}\")\n",
    "# print(f\"rmse {best_rmse['rmse']}\")\n",
    "# print(f\"mae {best_rmse['mae']}\")\n",
    "# print(f\"mape {np.round(best_rmse['mape'], 2) }%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_last = RandomForestRegressor( )\n",
    "# model_last.fit(pd.concat([x_train,x_val], ignore_index=True), pd.concat([y_train,y_val], ignore_index=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Previsão sobre os dados de treino\n",
    "# yhat_train = model_last.predict( x_train )\n",
    "# r2_train = mt.r2_score(y_train, yhat_train)\n",
    "# mse_train  = mt.mean_squared_error( y_train, yhat_train )  \n",
    "# rmse_train = mt.root_mean_squared_error(y_train,yhat_train)\n",
    "# mae  = mt.mean_absolute_error( y_train, yhat_train )\n",
    "# mape = mt.mean_absolute_percentage_error( y_train,yhat_train )\n",
    "\n",
    "\n",
    "# print(f\"r2_train: {r2_train}\")\n",
    "# print(f\"mse_train: {mse_train}\")\n",
    "# print(f\"rmse_train: {rmse_train}\")\n",
    "# print(f\"mae_train: {mae}\")\n",
    "# print(f'mape_train: {mape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Previsão sobre os dados de treino\n",
    "# yhat_val = model_last.predict( x_val )\n",
    "# r2_val = mt.r2_score(y_val, yhat_val)\n",
    "# mse_val  = mt.mean_squared_error( y_val, yhat_val )  \n",
    "# rmse_val = mt.root_mean_squared_error(y_val,yhat_val)\n",
    "# mae  = mt.mean_absolute_error( y_val, yhat_val )\n",
    "# mape = mt.mean_absolute_percentage_error( y_val,yhat_val )\n",
    "\n",
    "\n",
    "# print(f\"r2_val: {r2_val}\")\n",
    "# print(f\"mse_val: {mse_val}\")\n",
    "# print(f\"rmse_val: {rmse_val}\")\n",
    "# print(f\"mae_val: {mae}\")\n",
    "# print(f'mape_val: {mape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Previsão sobre os dados de treino\n",
    "# yhat_test = model_last.predict( x_test )\n",
    "# r2_test = mt.r2_score(y_test, yhat_test)\n",
    "# mse_test  = mt.mean_squared_error( y_test, yhat_test )  \n",
    "# rmse_test = mt.root_mean_squared_error(y_test,yhat_test)\n",
    "# mae  = mt.mean_absolute_error( y_test, yhat_test )\n",
    "# mape = mt.mean_absolute_percentage_error( y_test,yhat_test )\n",
    "\n",
    "\n",
    "# print(f\"r2_test: {r2_test}\")\n",
    "# print(f\"mse_test: {mse_test}\")\n",
    "# print(f\"rmse_test: {rmse_test}\")\n",
    "# print(f\"mae_test: {mae}\")\n",
    "# print(f'mape_test: {mape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polinomial Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Definir um intervalo de graus para testar\n",
    "# degree_range = range(1, 5)  # Ajuste o intervalo conforme necessário\n",
    "\n",
    "# # Armazenar as métricas para cada grau\n",
    "# best_degree = 0\n",
    "# best_r2 = float('-inf')  # Inicia com um valor muito baixo\n",
    "# metrics = []\n",
    "\n",
    "# for degree in degree_range:\n",
    "#     # 1. Escalonar os dados de treino\n",
    "#     scaler = StandardScaler()\n",
    "#     x_train_scaled = scaler.fit_transform(x_train)\n",
    "    \n",
    "#     # 2. Aplicar a transformação polinomial\n",
    "#     poly_features = PolynomialFeatures(degree=degree)\n",
    "#     x_train_poly = poly_features.fit_transform(x_train_scaled)\n",
    "    \n",
    "#     # 3. Treinar o modelo\n",
    "#     model = LinearRegression()\n",
    "#     model.fit(x_train_poly, y_train)\n",
    "    \n",
    "#     # 4. Escalonar os dados de validação\n",
    "#     x_val_scaled = scaler.transform(x_val)\n",
    "    \n",
    "#     # 5. Aplicar a transformação polinomial nos dados de validação\n",
    "#     x_val_poly = poly_features.transform(x_val_scaled)\n",
    "    \n",
    "#     # 6. Fazer as previsões\n",
    "#     yhat_val = model.predict(x_val_poly)\n",
    "    \n",
    "#     # 7. Calcular as métricas de avaliação\n",
    "#     r2_score = mt.r2_score(y_val, yhat_val)\n",
    "#     mse = mt.mean_squared_error(y_val, yhat_val)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     mae = mt.mean_absolute_error(y_val, yhat_val)\n",
    "#     mape = mt.mean_absolute_percentage_error(y_val, yhat_val)\n",
    "    \n",
    "#     # Armazenar os resultados\n",
    "#     metrics.append((degree, r2_score, mse, rmse, mae, mape))\n",
    "    \n",
    "#     # Atualizar o melhor valor de degree\n",
    "#     if r2_score > best_r2:\n",
    "#         best_r2 = r2_score\n",
    "#         best_degree = degree\n",
    "\n",
    "# # Exibir os resultados\n",
    "# print(f'Melhor grau polinomial: {best_degree} com R² = {best_r2}')\n",
    "# print(f'Métricas por grau:')\n",
    "# for metric in metrics:\n",
    "#     degree, r2, mse, rmse, mae, mape = metric\n",
    "#     print(f'Degree: {degree} -> R²: {r2}, MSE: {mse}, RMSE: {rmse}, MAE: {mae}, MAPE: {mape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Escalonar os dados de treino\n",
    "# scaler = StandardScaler()\n",
    "# x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# # 2. Escalonar os dados de validação\n",
    "# x_val_scaled = scaler.transform(x_val)\n",
    "\n",
    "# # 3. Aplicar a transformação polinomial\n",
    "# poly_features = PolynomialFeatures(degree=3)\n",
    "# x_train_poly = poly_features.fit_transform(x_train_scaled)\n",
    "\n",
    "# # 4. Aplicar a transformação polinomial nos dados de validação (apenas transform)\n",
    "# x_val_poly = poly_features.transform(x_val_scaled)\n",
    "\n",
    "# # 5. Combinar os dados de treino e validação\n",
    "# x_combined = np.concatenate([x_train_poly, x_val_poly])\n",
    "# y_combined = pd.concat([y_train, y_val], ignore_index=True)\n",
    "\n",
    "# # 6. Treinar o modelo com os dados combinados\n",
    "# model_last = LinearRegression()\n",
    "# model_last.fit(x_combined, y_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer a previsão nos dados de treino combinados\n",
    "# yhat_train = model_last.predict(x_train_poly)\n",
    "\n",
    "# # Calcular as métricas de avaliação nos dados de treino\n",
    "# r2_score_train = mt.r2_score(y_train, yhat_train)\n",
    "# mse_train = mt.mean_squared_error(y_train, yhat_train)\n",
    "# rmse_train = np.sqrt(mse_train)\n",
    "# mae_train = mt.mean_absolute_error(y_train, yhat_train)\n",
    "# mape_train = mt.mean_absolute_percentage_error(y_train, yhat_train)\n",
    "\n",
    "# print(f'Treino - R²: {r2_score_train}, MSE: {mse_train}, RMSE: {rmse_train}, MAE: {mae_train}, MAPE: {mape_train}')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fazer a previsão nos dados de validação\n",
    "# yhat_val = model_last.predict(x_val_poly)\n",
    "\n",
    "# # Calcular as métricas de avaliação nos dados de validação\n",
    "# r2_score_val = mt.r2_score(y_val, yhat_val)\n",
    "# mse_val = mt.mean_squared_error(y_val, yhat_val)\n",
    "# rmse_val = np.sqrt(mse_val)\n",
    "# mae_val = mt.mean_absolute_error(y_val, yhat_val)\n",
    "# mape_val = mt.mean_absolute_percentage_error(y_val, yhat_val)\n",
    "\n",
    "# print(f'Validação - R²: {r2_score_val}, MSE: {mse_val}, RMSE: {rmse_val}, MAE: {mae_val}, MAPE: {mape_val}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Escalonar os dados de teste usando o mesmo scaler ajustado no conjunto de treino\n",
    "# x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# # 2. Aplicar a transformação polinomial nos dados de teste (somente transform)\n",
    "# x_test_poly = poly_features.transform(x_test_scaled)\n",
    "\n",
    "# # 3. Fazer as previsões nos dados de teste\n",
    "# yhat_test = model_last.predict(x_test_poly)\n",
    "\n",
    "# # 4. Calcular as métricas de avaliação nos dados de teste\n",
    "# r2_score_test = mt.r2_score(y_test, yhat_test)\n",
    "# mse_test = mt.mean_squared_error(y_test, yhat_test)\n",
    "# rmse_test = np.sqrt(mse_test)\n",
    "# mae_test = mt.mean_absolute_error(y_test, yhat_test)\n",
    "# mape_test = mt.mean_absolute_percentage_error(y_test, yhat_test)\n",
    "\n",
    "# # 5. Exibir os resultados\n",
    "# print(f'Teste - R²: {r2_score_test:.4f}, MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}, MAPE: {mape_test:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressao Linear Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Escalonar os dados de treino\n",
    "# scaler = StandardScaler()\n",
    "# x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# # 2. Escalonar os dados de validação e teste\n",
    "# x_val_scaled = scaler.transform(x_val)\n",
    "# x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# # 3. Aplicar a transformação polinomial (se necessário)\n",
    "# degree = 3  # Grau do polinômio (ajustável)\n",
    "# poly_features = PolynomialFeatures(degree=degree)\n",
    "\n",
    "# x_train_poly = poly_features.fit_transform(x_train_scaled)\n",
    "# x_val_poly = poly_features.transform(x_val_scaled)\n",
    "# x_test_poly = poly_features.transform(x_test_scaled)\n",
    "\n",
    "# # 4. Concatenar os dados de treino e validação\n",
    "# x_combined = np.concatenate([x_train_poly, x_val_poly])\n",
    "# y_combined = pd.concat([y_train, y_val], ignore_index=True)\n",
    "\n",
    "# # 5. Treinar o modelo final com Lasso\n",
    "# alpha = 0.1  # Parâmetro de regularização (ajustável)\n",
    "# model_last = Lasso(alpha=alpha)\n",
    "# model_last.fit(x_combined, y_combined)\n",
    "\n",
    "# # 6. Fazer previsões no conjunto de treino, validação e teste\n",
    "# yhat_train = model_last.predict(x_train_poly)\n",
    "# yhat_val = model_last.predict(x_val_poly)\n",
    "# yhat_test = model_last.predict(x_test_poly)\n",
    "\n",
    "# # 7. Calcular as métricas de avaliação nos dados de treino, validação e teste\n",
    "# def calculate_metrics(y_true, y_pred, dataset_name):\n",
    "#     r2 = mt.r2_score(y_true, y_pred)\n",
    "#     mse = mt.mean_squared_error(y_true, y_pred)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     mae = mt.mean_absolute_error(y_true, y_pred)\n",
    "#     mape = mt.mean_absolute_percentage_error(y_true, y_pred)\n",
    "    \n",
    "#     print(f'{dataset_name} - R²: {r2:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.4f}')\n",
    "    \n",
    "# # Métricas para o conjunto de treino\n",
    "# calculate_metrics(y_train, yhat_train, \"Treino\")\n",
    "\n",
    "# # Métricas para o conjunto de validação\n",
    "# calculate_metrics(y_val, yhat_val, \"Validação\")\n",
    "\n",
    "# # Métricas para o conjunto de teste\n",
    "# calculate_metrics(y_test, yhat_test, \"Teste\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression L2 Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Escalonar os dados de treino\n",
    "# scaler = StandardScaler()\n",
    "# x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# # 2. Escalonar os dados de validação e teste\n",
    "# x_val_scaled = scaler.transform(x_val)\n",
    "# x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# # 3. Aplicar a transformação polinomial (se necessário)\n",
    "# degree = 2 # Grau do polinômio (ajustável)\n",
    "# poly_features = PolynomialFeatures(degree=degree)\n",
    "\n",
    "# x_train_poly = poly_features.fit_transform(x_train_scaled)\n",
    "# x_val_poly = poly_features.transform(x_val_scaled)\n",
    "# x_test_poly = poly_features.transform(x_test_scaled)\n",
    "\n",
    "# # 4. Concatenar os dados de treino e validação\n",
    "# x_combined = np.concatenate([x_train_poly, x_val_poly])\n",
    "# y_combined = pd.concat([y_train, y_val], ignore_index=True)\n",
    "\n",
    "# # 5. Treinar o modelo final com Ridge\n",
    "# alpha = 0.1  # Parâmetro de regularização (ajustável)\n",
    "# model_last = Ridge(alpha=alpha)\n",
    "# model_last.fit(x_combined, y_combined)\n",
    "\n",
    "# # 6. Fazer previsões no conjunto de treino, validação e teste\n",
    "# yhat_train = model_last.predict(x_train_poly)\n",
    "# yhat_val = model_last.predict(x_val_poly)\n",
    "# yhat_test = model_last.predict(x_test_poly)\n",
    "\n",
    "# # 7. Calcular as métricas de avaliação nos dados de treino, validação e teste\n",
    "# def calculate_metrics(y_true, y_pred, dataset_name):\n",
    "#     r2 = mt.r2_score(y_true, y_pred)\n",
    "#     mse = mt.mean_squared_error(y_true, y_pred)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     mae = mt.mean_absolute_error(y_true, y_pred)\n",
    "#     mape = mt.mean_absolute_percentage_error(y_true, y_pred)\n",
    "    \n",
    "#     print(f'{dataset_name} - R²: {r2:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.4f}')\n",
    "    \n",
    "# # Métricas para o conjunto de treino\n",
    "# calculate_metrics(y_train, yhat_train, \"Treino\")\n",
    "\n",
    "# # Métricas para o conjunto de validação\n",
    "# calculate_metrics(y_val, yhat_val, \"Validação\")\n",
    "\n",
    "# # Métricas para o conjunto de teste\n",
    "# calculate_metrics(y_test, yhat_test, \"Teste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Escalonar os dados de treino\n",
    "# scaler = StandardScaler()\n",
    "# x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# # 2. Escalonar os dados de validação e teste\n",
    "# x_val_scaled = scaler.transform(x_val)\n",
    "# x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# # 3. Aplicar a transformação polinomial (se necessário)\n",
    "# degree = 2  # Grau do polinômio (ajustável)\n",
    "# poly_features = PolynomialFeatures(degree=degree)\n",
    "\n",
    "# x_train_poly = poly_features.fit_transform(x_train_scaled)\n",
    "# x_val_poly = poly_features.transform(x_val_scaled)\n",
    "# x_test_poly = poly_features.transform(x_test_scaled)\n",
    "\n",
    "# # 4. Concatenar os dados de treino e validação\n",
    "# x_combined = np.concatenate([x_train_poly, x_val_poly])\n",
    "# y_combined = pd.concat([y_train, y_val], ignore_index=True)\n",
    "\n",
    "# # 5. Treinar o modelo final com Elastic Net\n",
    "# alpha = 0.1  # Parâmetro de regularização (ajustável)\n",
    "# l1_ratio = 0.5  # Razão entre L1 e L2 (0.5 significa 50% L1 e 50% L2)\n",
    "# model_last = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "# model_last.fit(x_combined, y_combined)\n",
    "\n",
    "# # 6. Fazer previsões no conjunto de treino, validação e teste\n",
    "# yhat_train = model_last.predict(x_train_poly)\n",
    "# yhat_val = model_last.predict(x_val_poly)\n",
    "# yhat_test = model_last.predict(x_test_poly)\n",
    "\n",
    "# # 7. Calcular as métricas de avaliação nos dados de treino, validação e teste\n",
    "# def calculate_metrics(y_true, y_pred, dataset_name):\n",
    "#     r2 = mt.r2_score(y_true, y_pred)\n",
    "#     mse = mt.mean_squared_error(y_true, y_pred)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     mae = mt.mean_absolute_error(y_true, y_pred)\n",
    "#     mape = mt.mean_absolute_percentage_error(y_true, y_pred)\n",
    "    \n",
    "#     print(f'{dataset_name} - R²: {r2:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.4f}')\n",
    "    \n",
    "# # Métricas para o conjunto de treino\n",
    "# calculate_metrics(y_train, yhat_train, \"Treino\")\n",
    "\n",
    "# # Métricas para o conjunto de validação\n",
    "# calculate_metrics(y_val, yhat_val, \"Validação\")\n",
    "\n",
    "# # Métricas para o conjunto de teste\n",
    "# calculate_metrics(y_test, yhat_test, \"Teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Polinomial com Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino - R²: 0.1176, MSE: 421.8097, RMSE: 20.5380, MAE: 16.2347, MAPE: 8.1579\n",
      "Validação - R²: 0.1079, MSE: 425.9973, RMSE: 20.6397, MAE: 16.3585, MAPE: 8.4787\n",
      "Teste - R²: 0.0702, MSE: 452.7136, RMSE: 21.2771, MAE: 16.7293, MAPE: 8.2095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemerv/.pyenv/versions/fundamentos_ml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.354e+03, tolerance: 7.200e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# # 1. Escalonar os dados de treino\n",
    "# scaler = StandardScaler()\n",
    "# x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# # 2. Escalonar os dados de validação e teste\n",
    "# x_val_scaled = scaler.transform(x_val)\n",
    "# x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# # 3. Aplicar a transformação polinomial\n",
    "# degree = 3  # Grau do polinômio (ajustável)\n",
    "# poly_features = PolynomialFeatures(degree=degree)\n",
    "\n",
    "# x_train_poly = poly_features.fit_transform(x_train_scaled)\n",
    "# x_val_poly = poly_features.transform(x_val_scaled)\n",
    "# x_test_poly = poly_features.transform(x_test_scaled)\n",
    "\n",
    "# # 4. Concatenar os dados de treino e validação\n",
    "# x_combined = np.concatenate([x_train_poly, x_val_poly])\n",
    "# y_combined = pd.concat([y_train, y_val], ignore_index=True)\n",
    "\n",
    "# # 5. Treinar o modelo final com Lasso\n",
    "# alpha = 0.1  # Parâmetro de regularização (ajustável)\n",
    "# model_lasso = Lasso(alpha=alpha)\n",
    "# model_lasso.fit(x_combined, y_combined)\n",
    "\n",
    "# # 6. Fazer previsões no conjunto de treino, validação e teste\n",
    "# yhat_train = model_lasso.predict(x_train_poly)\n",
    "# yhat_val = model_lasso.predict(x_val_poly)\n",
    "# yhat_test = model_lasso.predict(x_test_poly)\n",
    "\n",
    "# # 7. Calcular as métricas de avaliação nos dados de treino, validação e teste\n",
    "# def calculate_metrics(y_true, y_pred, dataset_name):\n",
    "#     r2 = mt.r2_score(y_true, y_pred)\n",
    "#     mse = mt.mean_squared_error(y_true, y_pred)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     mae = mt.mean_absolute_error(y_true, y_pred)\n",
    "#     mape = mt.mean_absolute_percentage_error(y_true, y_pred)\n",
    "    \n",
    "#     print(f'{dataset_name} - R²: {r2:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.4f}')\n",
    "    \n",
    "# # Métricas para o conjunto de treino\n",
    "# calculate_metrics(y_train, yhat_train, \"Treino\")\n",
    "\n",
    "# # Métricas para o conjunto de validação\n",
    "# calculate_metrics(y_val, yhat_val, \"Validação\")\n",
    "\n",
    "# # Métricas para o conjunto de teste\n",
    "# calculate_metrics(y_test, yhat_test, \"Teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Polinomial com Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino - R²: 0.1407, MSE: 410.7667, RMSE: 20.2674, MAE: 16.0405, MAPE: 7.9026\n",
      "Validação - R²: 0.1327, MSE: 414.1413, RMSE: 20.3505, MAE: 16.1489, MAPE: 8.3093\n",
      "Teste - R²: 0.0214, MSE: 476.4954, RMSE: 21.8288, MAE: 16.8583, MAPE: 7.9765\n"
     ]
    }
   ],
   "source": [
    "# # 1. Escalonar os dados de treino\n",
    "# scaler = StandardScaler()\n",
    "# x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# # 2. Escalonar os dados de validação e teste\n",
    "# x_val_scaled = scaler.transform(x_val)\n",
    "# x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# # 3. Aplicar a transformação polinomial\n",
    "# degree = 3  # Grau do polinômio (ajustável)\n",
    "# poly_features = PolynomialFeatures(degree=degree)\n",
    "\n",
    "# x_train_poly = poly_features.fit_transform(x_train_scaled)\n",
    "# x_val_poly = poly_features.transform(x_val_scaled)\n",
    "# x_test_poly = poly_features.transform(x_test_scaled)\n",
    "\n",
    "# # 4. Concatenar os dados de treino e validação\n",
    "# x_combined = np.concatenate([x_train_poly, x_val_poly])\n",
    "# y_combined = pd.concat([y_train, y_val], ignore_index=True)\n",
    "\n",
    "# # 5. Treinar o modelo final com Ridge\n",
    "# alpha = 0.1  # Parâmetro de regularização (ajustável)\n",
    "# model_ridge = Ridge(alpha=alpha)\n",
    "# model_ridge.fit(x_combined, y_combined)\n",
    "\n",
    "# # 6. Fazer previsões no conjunto de treino, validação e teste\n",
    "# yhat_train = model_ridge.predict(x_train_poly)\n",
    "# yhat_val = model_ridge.predict(x_val_poly)\n",
    "# yhat_test = model_ridge.predict(x_test_poly)\n",
    "\n",
    "# # 7. Calcular as métricas de avaliação nos dados de treino, validação e teste\n",
    "# def calculate_metrics(y_true, y_pred, dataset_name):\n",
    "#     r2 = mt.r2_score(y_true, y_pred)\n",
    "#     mse = mt.mean_squared_error(y_true, y_pred)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     mae = mt.mean_absolute_error(y_true, y_pred)\n",
    "#     mape = mt.mean_absolute_percentage_error(y_true, y_pred)\n",
    "    \n",
    "#     print(f'{dataset_name} - R²: {r2:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.4f}')\n",
    "    \n",
    "# # Métricas para o conjunto de treino\n",
    "# calculate_metrics(y_train, yhat_train, \"Treino\")\n",
    "\n",
    "# # Métricas para o conjunto de validação\n",
    "# calculate_metrics(y_val, yhat_val, \"Validação\")\n",
    "\n",
    "# # Métricas para o conjunto de teste\n",
    "# calculate_metrics(y_test, yhat_test, \"Teste\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fundamentos_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
